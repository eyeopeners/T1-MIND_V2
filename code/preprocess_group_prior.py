# preprocess_group_prior.py - CSVæ ¼å¼ç‰ˆæœ¬

import numpy as np
import pandas as pd
from pathlib import Path
from tqdm import tqdm
from scipy.stats import f_oneway
import warnings
warnings.filterwarnings('ignore')

# ==================== é…ç½® ====================
ADNI_MANIFEST = r"C:\T1+MIND_V2\data\ADNI\manifest_train.csv"
SAVE_PATH = r"C:\T1+MIND_V2\code\group_priors"

def load_single_mind_matrix(mind_path):
    """
    åŠ è½½å•ä¸ªMINDçŸ©é˜µï¼ˆCSVæ ¼å¼ï¼‰
    
    CSVæ ¼å¼è¯´æ˜ï¼š
    - ç¬¬ä¸€è¡Œï¼šç©ºå€¼, lh_L-181, lh_L-182, ..., rh_R-180
    - ç¬¬ä¸€åˆ—ï¼šlh_L-181, lh_L-182, ..., rh_R-180
    - æ•°å€¼éƒ¨åˆ†ï¼š[360, 360]çš„è·ç¦»çŸ©é˜µï¼Œå¯¹è§’çº¿ä¸º0
    
    Args:
        mind_path: MINDçŸ©é˜µCSVæ–‡ä»¶è·¯å¾„
        
    Returns:
        mind_matrix: [360, 360] çš„numpyæ•°ç»„
    """
    try:
        # ä½¿ç”¨pandasè¯»å–CSV
        # index_col=0 è¡¨ç¤ºç¬¬ä¸€åˆ—ä½œä¸ºç´¢å¼•
        df = pd.read_csv(mind_path, index_col=0)
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        mind_numeric = df.values.astype(np.float32)
        
        # éªŒè¯å½¢çŠ¶
        expected_shape = (360, 360)
        if mind_numeric.shape != expected_shape:
            raise ValueError(
                f"Expected shape {expected_shape}, got {mind_numeric.shape} "
                f"in file {mind_path}"
            )
        
        # éªŒè¯å¯¹è§’çº¿ä¸º0
        diag_vals = np.diag(mind_numeric)
        if not np.allclose(diag_vals, 0, atol=1e-6):
            # è­¦å‘Šä½†ä¸ç»ˆæ­¢
            # print(f"Warning: Diagonal not exactly zero in {Path(mind_path).name}, forcing to zero")
            np.fill_diagonal(mind_numeric, 0)
        
        # éªŒè¯å¯¹ç§°æ€§ï¼ˆMINDçŸ©é˜µåº”è¯¥æ˜¯å¯¹ç§°çš„ï¼‰
        if not np.allclose(mind_numeric, mind_numeric.T, atol=1e-4):
            # å¦‚æœä¸å¯¹ç§°ï¼Œå¯¹ç§°åŒ–
            # print(f"Warning: Matrix not symmetric in {Path(mind_path).name}, symmetrizing")
            mind_numeric = (mind_numeric + mind_numeric.T) / 2
        
        # æ£€æŸ¥æ˜¯å¦æœ‰NaNæˆ–Inf
        if np.isnan(mind_numeric).any():
            nan_count = np.isnan(mind_numeric).sum()
            print(f"Warning: {nan_count} NaN values found in {Path(mind_path).name}, replacing with 0")
            mind_numeric = np.nan_to_num(mind_numeric, nan=0.0)
        
        if np.isinf(mind_numeric).any():
            inf_count = np.isinf(mind_numeric).sum()
            print(f"Warning: {inf_count} Inf values found in {Path(mind_path).name}, replacing with 0")
            mind_numeric = np.nan_to_num(mind_numeric, posinf=0.0, neginf=0.0)
        
        # éªŒè¯æ•°å€¼èŒƒå›´ï¼ˆMINDè·ç¦»åº”è¯¥æ˜¯éè´Ÿçš„ï¼‰
        if (mind_numeric < 0).any():
            neg_count = (mind_numeric < 0).sum()
            print(f"Warning: {neg_count} negative values found in {Path(mind_path).name}, taking absolute")
            mind_numeric = np.abs(mind_numeric)
        
        return mind_numeric
        
    except FileNotFoundError:
        raise FileNotFoundError(f"MIND file not found: {mind_path}")
    except pd.errors.EmptyDataError:
        raise ValueError(f"Empty CSV file: {mind_path}")
    except Exception as e:
        raise Exception(f"Error loading {mind_path}: {str(e)}")


def load_mind_matrices(manifest_path, split='train'):
    """
    ä»manifeståŠ è½½æ‰€æœ‰MINDçŸ©é˜µ
    
    Returns:
        mind_dict: {
            'NC': [N_nc, 360, 360],
            'MCI': [N_mci, 360, 360],
            'AD': [N_ad, 360, 360]
        }
    """
    df = pd.read_csv(manifest_path)
    
    # å¦‚æœæœ‰splitåˆ—ï¼Œè¿‡æ»¤
    if 'split' in df.columns:
        df = df[df['split'] == split]
    
    mind_dict = {'NC': [], 'MCI': [], 'AD': []}
    label_map = {0: 'NC', 1: 'MCI', 2: 'AD'}
    
    print(f"\nLoading MIND matrices from {split} set...")
    print(f"Total samples: {len(df)}")
    print(f"  NC: {(df['label']==0).sum()}")
    print(f"  MCI: {(df['label']==1).sum()}")
    print(f"  AD: {(df['label']==2).sum()}")
    
    failed_loads = []
    success_count = {'NC': 0, 'MCI': 0, 'AD': 0}
    
    for idx, row in tqdm(df.iterrows(), total=len(df), desc="Loading MIND"):
        mind_path = row['mind_path']
        label = label_map[row['label']]
        
        try:
            mind = load_single_mind_matrix(mind_path)
            mind_dict[label].append(mind)
            success_count[label] += 1
        except Exception as e:
            error_msg = str(e)
            # åªä¿å­˜ç®€çŸ­çš„é”™è¯¯ä¿¡æ¯
            failed_loads.append({
                'path': mind_path,
                'label': label,
                'error': error_msg[:100]  # æˆªæ–­é•¿é”™è¯¯ä¿¡æ¯
            })
            continue
    
    print(f"\n{'='*60}")
    print("Loading Summary:")
    print(f"{'='*60}")
    for key in ['NC', 'MCI', 'AD']:
        total = (df['label'] == {'NC': 0, 'MCI': 1, 'AD': 2}[key]).sum()
        success = success_count[key]
        print(f"{key}: {success}/{total} ({success/total*100:.1f}%) loaded successfully")
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    for key in mind_dict:
        if len(mind_dict[key]) > 0:
            mind_dict[key] = np.stack(mind_dict[key], axis=0)
            print(f"\n{key} array shape: {mind_dict[key].shape}")
            print(f"  Mean: {mind_dict[key].mean():.4f}")
            print(f"  Std: {mind_dict[key].std():.4f}")
            print(f"  Range: [{mind_dict[key].min():.4f}, {mind_dict[key].max():.4f}]")
        else:
            raise ValueError(f"No {key} samples loaded! Check your data paths.")
    
    if failed_loads:
        print(f"\n{'='*60}")
        print(f"âš ï¸ Failed to load {len(failed_loads)} files")
        print(f"{'='*60}")
        
        # æŒ‰ç±»åˆ«ç»Ÿè®¡å¤±è´¥æ•°
        fail_by_label = {'NC': 0, 'MCI': 0, 'AD': 0}
        for fail in failed_loads:
            fail_by_label[fail['label']] += 1
        
        print("Failed by label:")
        for key in ['NC', 'MCI', 'AD']:
            if fail_by_label[key] > 0:
                print(f"  {key}: {fail_by_label[key]} files")
        
        # æ˜¾ç¤ºå‰5ä¸ªå¤±è´¥æ¡ˆä¾‹
        print("\nFirst 5 failed cases:")
        for i, fail in enumerate(failed_loads[:5]):
            print(f"  {i+1}. {Path(fail['path']).name}")
            print(f"     Label: {fail['label']}")
            print(f"     Error: {fail['error']}")
        
        # ä¿å­˜å®Œæ•´å¤±è´¥åˆ—è¡¨
        fail_df = pd.DataFrame(failed_loads)
        fail_path = Path(SAVE_PATH) / 'failed_loads.csv'
        fail_path.parent.mkdir(parents=True, exist_ok=True)
        fail_df.to_csv(fail_path, index=False)
        print(f"\n  Full list saved to: {fail_path}")
    
    return mind_dict


def compute_statistical_prior(mind_dict):
    """
    è®¡ç®—ç»Ÿè®¡å­¦å…ˆéªŒï¼ˆANOVA + FDRæ ¡æ­£ï¼‰
    
    Returns:
        prior_stat: [360, 360] - ç»Ÿè®¡å…ˆéªŒæƒé‡
    """
    print("\n" + "="*60)
    print("Computing statistical prior (ANOVA)...")
    print("="*60)
    
    nc_mind = mind_dict['NC']    # [N_nc, 360, 360]
    mci_mind = mind_dict['MCI']  # [N_mci, 360, 360]
    ad_mind = mind_dict['AD']    # [N_ad, 360, 360]
    
    N_nc, N_mci, N_ad = len(nc_mind), len(mci_mind), len(ad_mind)
    print(f"Sample sizes: NC={N_nc}, MCI={N_mci}, AD={N_ad}")
    
    # å¯¹æ¯æ¡è¾¹è¿›è¡ŒANOVA
    prior_stat = np.zeros((360, 360), dtype=np.float32)
    p_values_all = []
    positions_all = []
    
    print("\nPerforming ANOVA for each edge...")
    for i in tqdm(range(360), desc="ANOVA"):
        for j in range(i+1, 360):  # åªè®¡ç®—ä¸Šä¸‰è§’ï¼ˆå¯¹ç§°çŸ©é˜µï¼‰
            # ä¸‰ç»„åœ¨è¾¹(i,j)ä¸Šçš„å€¼
            nc_vals = nc_mind[:, i, j]
            mci_vals = mci_mind[:, i, j]
            ad_vals = ad_mind[:, i, j]
            
            # ANOVAæ£€éªŒ
            try:
                f_stat, p_val = f_oneway(nc_vals, mci_vals, ad_vals)
                
                # ä¿å­˜på€¼å’Œä½ç½®ï¼Œç”¨äºFDRæ ¡æ­£
                p_values_all.append(p_val)
                positions_all.append((i, j))
                
            except Exception as e:
                # å¦‚æœANOVAå¤±è´¥ï¼ˆå¦‚æ–¹å·®ä¸º0ï¼‰ï¼Œpå€¼è®¾ä¸º1
                p_values_all.append(1.0)
                positions_all.append((i, j))
    
    # FDRæ ¡æ­£ï¼ˆBenjamini-Hochbergï¼‰
    print("\nApplying FDR correction (Î±=0.05)...")
    p_values_all = np.array(p_values_all)
    sorted_indices = np.argsort(p_values_all)
    n_tests = len(p_values_all)
    alpha = 0.05
    
    significant_count = 0
    for rank, idx in enumerate(sorted_indices):
        threshold = (rank + 1) / n_tests * alpha
        p_val = p_values_all[idx]
        
        if p_val <= threshold:
            # æ˜¾è‘—ï¼Œè®¡ç®—æƒé‡
            weight = -np.log10(p_val + 1e-10)
            i, j = positions_all[idx]
            prior_stat[i, j] = weight
            prior_stat[j, i] = weight
            significant_count += 1
        else:
            # ä¸å†æ˜¾è‘—ï¼Œåç»­çš„éƒ½ä¸æ˜¾è‘—
            break
    
    # å½’ä¸€åŒ–åˆ°[0, 1]
    max_weight = prior_stat.max()
    if max_weight > 0:
        prior_stat = prior_stat / max_weight
    
    print(f"\nStatistical prior computed:")
    print(f"  Significant edges: {significant_count} / {n_tests} ({significant_count/n_tests*100:.2f}%)")
    print(f"  Mean weight (non-zero): {prior_stat[prior_stat > 0].mean():.4f}")
    
    return prior_stat


def compute_effect_size_prior(mind_dict):
    """
    è®¡ç®—æ•ˆåº”é‡å…ˆéªŒï¼ˆCohen's dï¼‰
    
    Returns:
        prior_effect: [360, 360] - æ•ˆåº”é‡å…ˆéªŒ
    """
    print("\n" + "="*60)
    print("Computing effect size prior (Cohen's d)...")
    print("="*60)
    
    nc_mind = mind_dict['NC']
    mci_mind = mind_dict['MCI']
    ad_mind = mind_dict['AD']
    
    prior_effect = np.zeros((360, 360), dtype=np.float32)
    
    print("\nComputing effect sizes...")
    for i in tqdm(range(360), desc="Effect Size"):
        for j in range(i+1, 360):
            nc_vals = nc_mind[:, i, j]
            mci_vals = mci_mind[:, i, j]
            ad_vals = ad_mind[:, i, j]
            
            # ä¸‰ä¸ªé…å¯¹æ¯”è¾ƒçš„Cohen's d
            # NC vs AD
            mean_diff_na = np.abs(nc_vals.mean() - ad_vals.mean())
            pooled_std_na = np.sqrt((nc_vals.var() + ad_vals.var()) / 2)
            d_na = mean_diff_na / (pooled_std_na + 1e-8)
            
            # NC vs MCI
            mean_diff_nm = np.abs(nc_vals.mean() - mci_vals.mean())
            pooled_std_nm = np.sqrt((nc_vals.var() + mci_vals.var()) / 2)
            d_nm = mean_diff_nm / (pooled_std_nm + 1e-8)
            
            # MCI vs AD
            mean_diff_ma = np.abs(mci_vals.mean() - ad_vals.mean())
            pooled_std_ma = np.sqrt((mci_vals.var() + ad_vals.var()) / 2)
            d_ma = mean_diff_ma / (pooled_std_ma + 1e-8)
            
            # å–æœ€å¤§æ•ˆåº”é‡
            max_d = max(d_na, d_nm, d_ma)
            
            prior_effect[i, j] = max_d
            prior_effect[j, i] = max_d
    
    # å½’ä¸€åŒ–
    max_effect = prior_effect.max()
    if max_effect > 0:
        prior_effect = prior_effect / max_effect
    
    print(f"\nEffect size prior computed:")
    print(f"  Max effect size: {prior_effect.max():.4f}")
    print(f"  Mean effect size (non-zero): {prior_effect[prior_effect > 0].mean():.4f}")
    print(f"  Large effects (d>0.8): {(prior_effect > 0.8).sum() / 2:.0f} edges")
    
    return prior_effect


def compute_network_topology_prior(mind_dict):
    """
    è®¡ç®—ç½‘ç»œæ‹“æ‰‘å…ˆéªŒï¼ˆå˜å¼‚ç³»æ•°ï¼‰
    
    Returns:
        prior_topo: [360, 360] - æ‹“æ‰‘å…ˆéªŒ
    """
    print("\n" + "="*60)
    print("Computing network topology prior...")
    print("="*60)
    
    nc_mind = mind_dict['NC']
    mci_mind = mind_dict['MCI']
    ad_mind = mind_dict['AD']
    
    prior_topo = np.zeros((360, 360), dtype=np.float32)
    
    print("\nComputing coefficient of variation across groups...")
    for i in tqdm(range(360), desc="Topology"):
        for j in range(i+1, 360):
            # ä¸‰ç»„çš„å‡å€¼
            nc_mean = nc_mind[:, i, j].mean()
            mci_mean = mci_mind[:, i, j].mean()
            ad_mean = ad_mind[:, i, j].mean()
            
            means = np.array([nc_mean, mci_mean, ad_mean])
            
            # å˜å¼‚ç³»æ•°
            cv = means.std() / (means.mean() + 1e-8)
            
            prior_topo[i, j] = cv
            prior_topo[j, i] = cv
    
    # å½’ä¸€åŒ–
    max_cv = prior_topo.max()
    if max_cv > 0:
        prior_topo = prior_topo / max_cv
    
    print(f"\nTopology prior computed:")
    print(f"  Max CV: {prior_topo.max():.4f}")
    print(f"  Mean CV (non-zero): {prior_topo[prior_topo > 0].mean():.4f}")
    
    return prior_topo


def compute_and_save_group_prior(adni_manifest, save_dir):
    """
    å®Œæ•´æµç¨‹ï¼šåŠ è½½æ•°æ® â†’ è®¡ç®—ä¸‰ç§å…ˆéªŒ â†’ èåˆ â†’ ä¿å­˜
    """
    save_dir = Path(save_dir)
    save_dir.mkdir(parents=True, exist_ok=True)
    
    print("="*60)
    print("Group Prior Computation Pipeline")
    print("="*60)
    print(f"Input manifest: {adni_manifest}")
    print(f"Output directory: {save_dir}")
    
    # 1. åŠ è½½MINDçŸ©é˜µ
    mind_dict = load_mind_matrices(adni_manifest, split='train')
    
    # éªŒè¯æ˜¯å¦æ‰€æœ‰ç±»åˆ«éƒ½æœ‰æ•°æ®
    for key in ['NC', 'MCI', 'AD']:
        if key not in mind_dict or len(mind_dict[key]) == 0:
            raise ValueError(f"No {key} samples found in training data!")
    
    # 2. è®¡ç®—ä¸‰ç§å…ˆéªŒ
    prior_stat = compute_statistical_prior(mind_dict)
    prior_effect = compute_effect_size_prior(mind_dict)
    prior_topo = compute_network_topology_prior(mind_dict)
    
    # 3. èåˆï¼ˆåŠ æƒå¹³å‡ï¼‰
    print("\n" + "="*60)
    print("Combining priors...")
    print("="*60)
    
    w_stat = 0.4
    w_effect = 0.3
    w_topo = 0.3
    
    combined_prior = (
        w_stat * prior_stat +
        w_effect * prior_effect +
        w_topo * prior_topo
    )
    
    # å†æ¬¡å½’ä¸€åŒ–åˆ°[0, 1]
    combined_prior = combined_prior / (combined_prior.max() + 1e-8)
    
    print(f"\nCombined prior statistics:")
    print(f"  Shape: {combined_prior.shape}")
    print(f"  Range: [{combined_prior.min():.4f}, {combined_prior.max():.4f}]")
    print(f"  Mean: {combined_prior.mean():.4f}")
    print(f"  Std: {combined_prior.std():.4f}")
    print(f"  Non-zero edges: {(combined_prior > 0).sum() / 2:.0f} / {360*359/2:.0f}")
    
    # 4. ä¿å­˜
    np.save(save_dir / 'statistical_prior.npy', prior_stat)
    np.save(save_dir / 'effect_size_prior.npy', prior_effect)
    np.save(save_dir / 'topology_prior.npy', prior_topo)
    np.save(save_dir / 'combined_prior.npy', combined_prior)
    
    print(f"\nâœ“ All priors saved to {save_dir}:")
    print(f"  - statistical_prior.npy")
    print(f"  - effect_size_prior.npy")
    print(f"  - topology_prior.npy")
    print(f"  - combined_prior.npy")
    
    # 5. å¯è§†åŒ–ï¼ˆå¯é€‰ï¼‰
    try:
        import matplotlib
        matplotlib.use('Agg')  # éäº¤äº’å¼åç«¯
        import matplotlib.pyplot as plt
        import seaborn as sns
        
        fig, axes = plt.subplots(2, 2, figsize=(16, 14))
        
        # ç»Ÿè®¡å…ˆéªŒ
        im1 = axes[0, 0].imshow(prior_stat, cmap='YlOrRd', aspect='auto')
        axes[0, 0].set_title('Statistical Prior (ANOVA + FDR)', fontsize=14, fontweight='bold')
        plt.colorbar(im1, ax=axes[0, 0])
        
        # æ•ˆåº”é‡å…ˆéªŒ
        im2 = axes[0, 1].imshow(prior_effect, cmap='YlOrRd', aspect='auto')
        axes[0, 1].set_title("Effect Size Prior (Cohen's d)", fontsize=14, fontweight='bold')
        plt.colorbar(im2, ax=axes[0, 1])
        
        # æ‹“æ‰‘å…ˆéªŒ
        im3 = axes[1, 0].imshow(prior_topo, cmap='YlOrRd', aspect='auto')
        axes[1, 0].set_title('Topology Prior (CV)', fontsize=14, fontweight='bold')
        plt.colorbar(im3, ax=axes[1, 0])
        
        # ç»„åˆå…ˆéªŒ
        im4 = axes[1, 1].imshow(combined_prior, cmap='YlOrRd', aspect='auto')
        axes[1, 1].set_title(f'Combined Prior (weights: {w_stat}, {w_effect}, {w_topo})', 
                            fontsize=14, fontweight='bold')
        plt.colorbar(im4, ax=axes[1, 1])
        
        plt.tight_layout()
        viz_path = save_dir / 'prior_visualization.png'
        plt.savefig(viz_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"  - prior_visualization.png")
        
    except ImportError:
        print("\nâš ï¸ matplotlib/seaborn not available, skipping visualization")
    except Exception as e:
        print(f"\nâš ï¸ Visualization failed: {str(e)}")
    
    return {
        'statistical': prior_stat,
        'effect_size': prior_effect,
        'topology': prior_topo,
        'combined': combined_prior
    }


if __name__ == "__main__":
    import sys
    
    try:
        # è¿è¡Œ
        prior_dict = compute_and_save_group_prior(ADNI_MANIFEST, SAVE_PATH)
        
        print("\n" + "="*60)
        print("ğŸ‰ Group prior computation completed successfully!")
        print("="*60)
        
    except Exception as e:
        print("\n" + "="*60)
        print("âŒ Error occurred:")
        print("="*60)
        print(f"{str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
